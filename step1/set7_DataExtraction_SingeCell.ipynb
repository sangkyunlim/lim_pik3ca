{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# type in the information in this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O:\\ImStor\\sorger\\data\\Cytell\\Kyun\\cycIF_analysis_python_v2\\set7_4CL_d234_ERcycD\\T47D_p6_ERcycD\n"
     ]
    }
   ],
   "source": [
    "# Input information in this cell\n",
    "\n",
    "## Cell name\n",
    "SelectedCellamong4CellLine = 'T47D'\n",
    "\n",
    "## Set number\n",
    "SetNumber = 'set7'\n",
    "\n",
    "## change directory\n",
    "\n",
    "os.chdir(r\"O:\\ImStor\\sorger\\data\\Cytell\\Kyun\\cycIF_analysis_python_v2\\set7_4CL_d234_ERcycD\\T47D_p6_ERcycD\")\n",
    "print(os.getcwd())\n",
    "\n",
    "\n",
    "## cycle number - how many rounds in cycIF?\n",
    "TotalCycleNumber = 2     #cycIF cycle number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load all Nuc*.txt files into a single dataframe.\n",
    "df_Nuc = pd.concat([\n",
    "    pd.read_table(path, index_col=0)\n",
    "    for path in glob.glob('Results-Nuc-*.txt')\n",
    "])\n",
    "\n",
    "\n",
    "# Parse the Label column into its components, in a new dataframe.\n",
    "label_Nuc = df_Nuc.Label.str.extract(r'([A-Z])(\\d\\d)_fld(\\d+):(\\d+)-(\\d+):(.*)',\n",
    "                                  expand=True)\n",
    "label_Nuc.columns = ['Row', 'Column', 'Field', 'ObjNum', 'Unknown', 'Channel']\n",
    "label_Nuc['Well'] = label_Nuc['Row'] + label_Nuc['Column']\n",
    "\n",
    "for f in  'Column', 'Field', 'ObjNum', 'Unknown':\n",
    "    label_Nuc[f] = label_Nuc[f].astype(int)\n",
    "\n",
    "# Append these new columns to the data.\n",
    "dfl_Nuc = pd.concat([label_Nuc, df_Nuc], axis=1)\n",
    "\n",
    "# Load all Cyto*.txt files into a single dataframe.\n",
    "df_Cyto = pd.concat([\n",
    "    pd.read_table(path, index_col=0)\n",
    "    for path in glob.glob('Results-Cyto-*.txt')\n",
    "])\n",
    "\n",
    "\n",
    "# Parse the Label column into its components, in a new dataframe.\n",
    "label_Cyto = df_Cyto.Label.str.extract(r'([A-Z])(\\d\\d)_fld(\\d+):(\\d+)-(\\d+):(.*)',\n",
    "                                  expand=True)\n",
    "label_Cyto.columns = ['Row', 'Column', 'Field', 'ObjNum', 'Unknown', 'Channel']\n",
    "label_Cyto['Well'] = label_Cyto['Row'] + label_Cyto['Column']\n",
    "\n",
    "for f in 'Column', 'Field', 'ObjNum', 'Unknown':\n",
    "    label_Cyto[f] = label_Cyto[f].astype(int)\n",
    "\n",
    "# Append these new columns to the data.\n",
    "dfl_Cyto = pd.concat([label_Cyto, df_Cyto], axis=1)\n",
    "\n",
    "# Choose columns that are informative\n",
    "## Nuclear intensity Summary\n",
    "Nuc_Sum = dfl_Nuc.loc[:,['Row','Column','Field','ObjNum','Channel','Well','Label','Area','Mean']]\n",
    "\n",
    "Nuc_Sum['Content'] = dfl_Nuc['Area']*dfl_Nuc['Mean']\n",
    "\n",
    "Nuc_cID = Nuc_Sum.Label.str.extract(r'([A-Z]\\d+_[f][l][d]\\d+:\\d+)(.*)',\n",
    "                                  expand=True)\n",
    "\n",
    "Nuc_cID.columns = ['CellID', '2ndPart']\n",
    "Nuc_Sum.index = Nuc_cID['CellID']\n",
    "\n",
    "\n",
    "## Cytoplasmic intensity Summary\n",
    "Cyto_Sum = dfl_Cyto.loc[:,['Row','Column','Field','ObjNum','Channel','Well','Label','Area','Mean']]\n",
    "\n",
    "Cyto_Sum['Content'] = dfl_Cyto['Area']*dfl_Cyto['Mean']\n",
    "\n",
    "Cyto_cID = Cyto_Sum.Label.str.extract(r'([A-Z]\\d+_[f][l][d]\\d+:\\d+)(.*)',\n",
    "                                  expand=True)\n",
    "\n",
    "Cyto_cID.columns = ['CellID', '2ndPart']\n",
    "Cyto_Sum.index = Cyto_cID['CellID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Merge dataframes (Nuc_Sum and Cyto_Sum) and metadata (two metadata files - Well and Staining)\n",
    "# change directory (move up)\n",
    "os.chdir('..')\n",
    "#print(os.getcwd())\n",
    "\n",
    "# obtain metadata files (Well and Staining)\n",
    "\n",
    "file1 = glob.glob('metadata_set*_Well.csv')\n",
    "file2 = glob.glob('metadata_set*_Staining.csv')\n",
    "\n",
    "MetadataWell = pd.read_csv(str(file1)[2:-2], index_col=False)\n",
    "MetadataStaining = pd.read_csv(str(file2)[2:-2], index_col=False)\n",
    "\n",
    "\n",
    "MetadataStaining['IDforMerge'] = MetadataStaining['Top/Bottom'] + ':' + MetadataStaining['Channel']\n",
    "\n",
    "\n",
    "# Combine Nuc_Sum and Cyto_Sum with metadata\n",
    "\n",
    "Nuc_temp = Nuc_Sum.merge(MetadataWell[['Top/Bottom', 'Treatment', 'Time']], \n",
    "                         left_on=Nuc_Sum['Well'], \n",
    "                         right_on=MetadataWell['Well'], \n",
    "                         how='outer')\n",
    "\n",
    "Cyto_temp = Cyto_Sum.merge(MetadataWell[['Top/Bottom', 'Treatment', 'Time']], \n",
    "                           left_on=Cyto_Sum['Well'], \n",
    "                           right_on=MetadataWell['Well'], \n",
    "                           how='outer')\n",
    "\n",
    "# add \"IDforMerge\" column to use for merging, and merge\n",
    "\n",
    "Nuc_temp['IDforMerge'] = Nuc_temp['Top/Bottom'] + ':' + Nuc_temp['Channel']\n",
    "Cyto_temp['IDforMerge'] = Cyto_temp['Top/Bottom'] + ':' + Cyto_temp['Channel']\n",
    "\n",
    "Nuc_Merged = Nuc_temp.merge(MetadataStaining[['Staining']], left_on=Nuc_temp['IDforMerge'], right_on=MetadataStaining['IDforMerge'], how='outer')\n",
    "Cyto_Merged = Cyto_temp.merge(MetadataStaining[['Staining']], left_on=Cyto_temp['IDforMerge'], right_on=MetadataStaining['IDforMerge'], how='outer')\n",
    "\n",
    "# add \"Compartment\" Column\n",
    "Nuc_Merged['Compartment'] =\"Nucleus\"\n",
    "Cyto_Merged['Compartment'] =\"Cytoplasm\"\n",
    "\n",
    "# Generate df_all, combining Nuc and Cyto info \n",
    "\n",
    "df1 = pd.concat([Nuc_Merged, Cyto_Merged])\n",
    "\n",
    "df1['Cell'] = SelectedCellamong4CellLine\n",
    "\n",
    "## save this first file if you want to check it out\n",
    "# firstfilename = SelectedCellamong4CellLine + '_' + SetNumber + '.csv'\n",
    "# df_all.to_csv(firstfilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single cell dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Design - dataframe of single cell (SCdesign)\n",
    "\n",
    "df1_cID = df1.Label.str.extract(r'([A-Z]\\d+_[f][l][d]\\d+:\\d+)(.*)',\n",
    "                                  expand=True)\n",
    "\n",
    "df1_cID.columns = ['CellID', '2ndPart']\n",
    "\n",
    "df1.index = df1_cID['CellID']\n",
    "\n",
    "SCdesign = df1.loc[df1['Channel']=='DAPI-0001'][['Row', 'Column', 'Field', 'ObjNum', 'Well',\n",
    "       'Label', 'Content', 'Top/Bottom', 'Treatment', 'Time', 'Compartment',\n",
    "       'IDforMerge', 'Cell',\n",
    "       ]]\n",
    "\n",
    "# make 'CellID' column\n",
    "SCdesign['CellID'] = SCdesign.index\n",
    "df1['CellID'] = df1.index\n",
    "\n",
    "# Fill in the antibody information\n",
    "\n",
    "Channel = pd.Series(['DAPI-0001', 'FITC-0001', 'Cy3-0001', 'Cy5-0001',\n",
    "                     'DAPI-0002', 'FITC-0002', 'Cy3-0002', 'Cy5-0002',\n",
    "                     'DAPI-0003', 'FITC-0003', 'Cy3-0003', 'Cy5-0003',\n",
    "                     'DAPI-0004', 'FITC-0004', 'Cy3-0004', 'Cy5-0004',\n",
    "                     ])\n",
    "\n",
    "\n",
    "# Make dataframe for each fluorochrome\n",
    "Group1 = df1.loc[(df1['Channel']==Channel[0] )][['CellID','Mean','Compartment']]\n",
    "Group2 = df1.loc[(df1['Channel']==Channel[1] )][['CellID','Mean','Compartment']]\n",
    "Group3 = df1.loc[(df1['Channel']==Channel[2] )][['CellID','Mean','Compartment']]\n",
    "Group4 = df1.loc[(df1['Channel']==Channel[3] )][['CellID','Mean','Compartment']]\n",
    "\n",
    "Group5 = df1.loc[(df1['Channel']==Channel[4] )][['CellID','Mean','Compartment']]\n",
    "Group6 = df1.loc[(df1['Channel']==Channel[5] )][['CellID','Mean','Compartment']]\n",
    "Group7 = df1.loc[(df1['Channel']==Channel[6] )][['CellID','Mean','Compartment']]\n",
    "Group8 = df1.loc[(df1['Channel']==Channel[7] )][['CellID','Mean','Compartment']]\n",
    "\n",
    "if TotalCycleNumber >= 3:\n",
    "    Group9 = df1.loc[(df1['Channel']==Channel[8] )][['CellID','Mean','Compartment']]\n",
    "    Group10 = df1.loc[(df1['Channel']==Channel[9] )][['CellID','Mean','Compartment']]\n",
    "    Group11 = df1.loc[(df1['Channel']==Channel[10] )][['CellID','Mean','Compartment']]\n",
    "    Group12 = df1.loc[(df1['Channel']==Channel[11] )][['CellID','Mean','Compartment']]\n",
    "    \n",
    "    if TotalCycleNumber >= 4:\n",
    "        Group13 = df1.loc[(df1['Channel']==Channel[12] )][['CellID','Mean','Compartment']]\n",
    "        Group14 = df1.loc[(df1['Channel']==Channel[13] )][['CellID','Mean','Compartment']]\n",
    "        Group15 = df1.loc[(df1['Channel']==Channel[14] )][['CellID','Mean','Compartment']]\n",
    "        Group16 = df1.loc[(df1['Channel']==Channel[15] )][['CellID','Mean','Compartment']]\n",
    "\n",
    "# combine them horizontally\n",
    "\n",
    "if TotalCycleNumber == 2:\n",
    "    Group_all = pd.concat([Group1, Group2, Group3, Group4, Group5, Group6, Group7, Group8], axis=1)\n",
    "elif TotalCycleNumber == 3:\n",
    "    Group_all = pd.concat([Group1, Group2, Group3, Group4, Group5, Group6, Group7, Group8, Group9, Group10, Group11, Group12], axis=1)\n",
    "elif TotalCycleNumber == 4:\n",
    "    Group_all = pd.concat([Group1, Group2, Group3, Group4, Group5, Group6, Group7, Group8, Group9, Group10, Group11, Group12, Group13, Group14, Group15, Group16], axis=1)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Intensity_all : select only intensity values\n",
    "\n",
    "Intensity_all = Group_all.iloc[:,1::3]\n",
    "\n",
    "Intensity_all.columns = list(Channel[:4*TotalCycleNumber])\n",
    "Intensity_all['CellID'] = Intensity_all.index\n",
    "\n",
    "# Merge SCdesign and Intensity\n",
    "df_SC_Merged = pd.concat([SCdesign, Intensity_all], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O:\\ImStor\\sorger\\data\\Cytell\\Kyun\\cycIF_analysis_python_v2\\set7_4CL_d234_ERcycD\n"
     ]
    }
   ],
   "source": [
    "# put Nuc and Cyto info horizontally\n",
    "\n",
    "Group_Nuc = df_SC_Merged.loc[(df_SC_Merged['Compartment']=='Nucleus')]\n",
    "Group_Cyto = df_SC_Merged.loc[(df_SC_Merged['Compartment']=='Cytoplasm')]\n",
    "\n",
    "List_column_Nuc = list(['Row', 'Column', 'Field', 'ObjNum', 'Well', 'Label', 'Content',\n",
    "       'Top/Bottom', 'Treatment', 'Time', 'Cell',\n",
    "       'CellID']) + list(Channel[:4*TotalCycleNumber])\n",
    "\n",
    "List_column_Cyto = list(Channel[:4*TotalCycleNumber]) + list(['CellID'])\n",
    "\n",
    "Group_Nuc_short = Group_Nuc[List_column_Nuc]\n",
    "Group_Cyto_short = Group_Cyto[List_column_Cyto]\n",
    "\n",
    "Group_both = pd.concat([Group_Nuc_short, Group_Cyto_short], axis=1)\n",
    "\n",
    "# divide dataframe if antibodies on Row BCD and Row EFG are different (set3-set7)\n",
    "\n",
    "df_BCD = Group_both[Group_both['Top/Bottom']=='BCD']\n",
    "df_EFG = Group_both[Group_both['Top/Bottom']=='EFG']\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# assign the antibody name to each fluorophore\n",
    "\n",
    "fileN = 'metadata_' + SetNumber + '_Staining.csv'\n",
    "meta_staining = pd.read_csv(fileN)\n",
    "\n",
    "# label for BCD and EFG\n",
    "Label_BCD_1 = meta_staining[meta_staining['Top/Bottom']=='BCD']['Staining'] + '_N'\n",
    "Label_BCD_2 = meta_staining[meta_staining['Top/Bottom']=='BCD']['Staining'] + '_C'\n",
    "\n",
    "Label_EFG_1 = meta_staining[meta_staining['Top/Bottom']=='EFG']['Staining'] + '_N'\n",
    "Label_EFG_2 = meta_staining[meta_staining['Top/Bottom']=='EFG']['Staining'] + '_C'\n",
    "\n",
    "Label_BCD = list(df_BCD.columns[:13]) + list(Label_BCD_1) + list(Label_BCD_2) + list(df_BCD.columns[-2:])\n",
    "Label_EFG = list(df_EFG.columns[:13]) + list(Label_EFG_1) + list(Label_EFG_2) + list(df_EFG.columns[-2:])\n",
    "\n",
    "df_BCD.columns = Label_BCD\n",
    "df_EFG.columns = Label_EFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save\n",
    "\n",
    "filename_BCD = 'SingleCell_' + SetNumber + '_' + SelectedCellamong4CellLine + '_BCD.csv'\n",
    "filename_EFG = 'SingleCell_' + SetNumber + '_' + SelectedCellamong4CellLine + '_EFG.csv'\n",
    "\n",
    "df_BCD.to_csv(filename_BCD)\n",
    "df_EFG.to_csv(filename_EFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
